# NL2SQL BigQuery Analytics Platform

**ìì—°ì–´ë¥¼ BigQuery SQLë¡œ ë³€í™˜í•˜ê³  ì‹¤í–‰í•˜ëŠ” ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ë¶„ì„ í”Œë«í¼**

FastAPI ë°±ì—”ë“œì™€ Vite+Vue3 í”„ë¡ íŠ¸ì—”ë“œë¡œ êµ¬ì„±ëœ í’€ìŠ¤íƒ NL2SQL ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.
LLM(OpenAI/Claude/Gemini)ê³¼ ì‹œë§¨í‹± ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ì •í™•í•œ SQLì„ ìƒì„±í•˜ê³ ,
6ë‹¨ê³„ ê²€ì¦ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ì•ˆì „í•˜ê²Œ ì‹¤í–‰í•©ë‹ˆë‹¤.

---

## ğŸŒŸ ì£¼ìš” ê¸°ëŠ¥

### ğŸ¤– í•˜ì´ë¸Œë¦¬ë“œ LLM ì•„í‚¤í…ì²˜
- **ë‹¤ì¤‘ LLM ì§€ì›**: OpenAI (gpt-4o-mini), Anthropic (Claude), Google (Gemini)
- **í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ**: ë¹ ë¥¸ í‚¤ì›Œë“œ ë§¤ì¹­ + LLM ë³´ì™„
- **ë¹„ìš© ìµœì í™”**: ê°„ë‹¨í•œ ì§ˆë¬¸ì€ ë¬´ë£Œ, ë³µì¡í•œ ì§ˆë¬¸ë§Œ LLM ì‚¬ìš©

### ğŸ“Š ì‹œë§¨í‹± ëª¨ë¸ ê¸°ë°˜
- **ì—”í‹°í‹°/ì°¨ì›/ì¸¡ì •í•­ëª©** ì •ì˜ë¡œ ì¼ê´€ëœ ë©”íŠ¸ë¦­ ê´€ë¦¬
- **ë©”íŠ¸ë¦­ ì •ì˜**: SQL í‘œí˜„ì‹ ë° ê¸°ë³¸ í•„í„° ì¤‘ì•™ ê´€ë¦¬
- **Few-shot í•™ìŠµ**: Golden queriesë¡œ SQL ìƒì„± í’ˆì§ˆ í–¥ìƒ
- **ë™ì˜ì–´ ì§€ì›**: ë‹¤ì–‘í•œ í‘œí˜„ì„ í‘œì¤€ ìš©ì–´ë¡œ ìë™ ë³€í™˜

### ğŸ›¡ï¸ 6ë‹¨ê³„ ê²€ì¦ íŒŒì´í”„ë¼ì¸
1. **Lint**: SQL í’ˆì§ˆ ê²€ì‚¬ (SELECT *, ì‹œê°„ í•„í„° ë“±)
2. **Dry Run**: BigQuery êµ¬ë¬¸ ê²€ì¦ ë° ë¹„ìš© ì¶”ì •
3. **Explain**: ì¿¼ë¦¬ ì‹¤í–‰ ê³„íš ë¶„ì„ (ì„ íƒì )
4. **Schema**: ê²°ê³¼ ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ (LIMIT 0)
5. **Canary**: ìƒ˜í”Œ ì‹¤í–‰ìœ¼ë¡œ ëŸ°íƒ€ì„ ì˜¤ë¥˜ ê°ì§€
6. **Domain Assertions**: ì‹œë§¨í‹± ëª¨ë¸ ê¸°ë°˜ ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦

### ğŸ”§ GA4 BigQuery Export íŠ¹í™”
- **í…Œì´ë¸” ì„œí”½ìŠ¤ ìë™ ì²˜ë¦¬**: `events_*` + `_TABLE_SUFFIX` ì¡°ê±´
- **ë„¤ìŠ¤í‹°ë“œ í•„ë“œ ì§€ì›**: `device.category`, `geo.country` ë“±
- **ì‹œê°„ ë²”ìœ„ ìë™ ê³„ì‚°**: "ì§€ë‚œ 7ì¼" â†’ `BETWEEN '20251031' AND '20251107'`
- **GA4 ìŠ¤í‚¤ë§ˆ í†µí•©**: ê³µì‹ ìŠ¤í‚¤ë§ˆ ì •ë³´ í”„ë¡¬í”„íŠ¸ì— í¬í•¨

### ğŸ’¬ ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤
- **ChatGPT ìŠ¤íƒ€ì¼ UI**: ìì—°ì–´ ëŒ€í™” ê¸°ë°˜
- **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°**: SSEë¡œ íŒŒì´í”„ë¼ì¸ ì§„í–‰ìƒí™© ì‹¤ì‹œê°„ í‘œì‹œ
- **ì»¨í…ìŠ¤íŠ¸ ìœ ì§€**: ì´ì „ ëŒ€í™” ë‚´ìš© ì°¸ì¡° ê°€ëŠ¥
- **ë§ˆí¬ë‹¤ìš´ ì§€ì›**: ê²°ê³¼ë¥¼ í‘œ/ì°¨íŠ¸ë¡œ ì‹œê°í™”

### ğŸ”’ ë³´ì•ˆ ë° ë¹„ìš© ê´€ë¦¬
- **ê°€ë“œë ˆì¼ ì •ì±…**: DELETE, UPDATE, INSERT, DROP ì°¨ë‹¨
- **ë¹„ìš© ì œí•œ**: `maximum_bytes_billed` ì„¤ì •
- **Dry Run ëª¨ë“œ**: ì‹¤ì œ ì‹¤í–‰ ì—†ì´ ë¹„ìš© ì¶”ì •
- **ì¿¼ë¦¬ êµ¬ì²´í™”**: ìì£¼ ì‚¬ìš©í•˜ëŠ” ì¿¼ë¦¬ ê²°ê³¼ ìºì‹±

---

### ê³ ê° í–‰ë™ ë„¤íŠ¸ì›Œí¬ (NEW)
- í”„ë¡ íŠ¸ ìƒë‹¨ íŒ¨ë„ì—ì„œ ê³ ê°êµ°(ì‹ ê·œ, ë°˜ë³µêµ¬ë§¤, VIP ë“±)ì„ ì„ íƒí•˜ë©´ í•´ë‹¹ ì„¸ê·¸ë¨¼íŠ¸ì˜ í–‰ë™ ë„¤íŠ¸ì›Œí¬ë¥¼ ì¦‰ì‹œ ë Œë”ë§í•©ë‹ˆë‹¤.
- ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì˜ `ê³ ê° ë„¤íŠ¸ì›Œí¬` ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ë„¤íŠ¸ì›Œí¬ í™”ë©´ìœ¼ë¡œ ì „í™˜ë˜ê³ , `ì±— ë³´ê¸°` ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ê¸°ì¡´ ëŒ€í™”í˜• UIë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.
- ë°±ì—”ë“œëŠ” `/api/network/customer-flow` ì—”ë“œí¬ì¸íŠ¸ë¥¼ í†µí•´ BigQueryì— íŒŒë¼ë¯¸í„°í™”ëœ WHERE ì ˆì„ êµ¬ì„±í•˜ê³  ì´ë²¤íŠ¸ ê°„ ì´ë™ íšŸìˆ˜ë¥¼ ì§‘ê³„í•œ ë’¤ `nodes + links` í˜•íƒœë¡œ ì‘ë‹µí•©ë‹ˆë‹¤.
- ì§€ì› íŒŒë¼ë¯¸í„°: `segment`(í•„ìˆ˜), `start_date`/`end_date`(ISO, ê¸°ë³¸ 14ì¼), `limit`(edge ê°œìˆ˜ ì œí•œ), `min_edge_count`(ë…¸ì´ì¦ˆ í•„í„°).
- ì„¸ê·¸ë¨¼íŠ¸ ëª©ë¡ì€ `/api/network/customer-flow/segments` ë¡œ ì¡°íšŒí•  ìˆ˜ ìˆìœ¼ë©° í”„ë¡ íŠ¸ëŠ” ì—¬ê¸°ì„œ default ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.

```json
POST /api/network/customer-flow
{
  "segment": "repeat_buyers",
  "start_date": "2025-10-15",
  "end_date": "2025-10-28"
}
```

```json
{
  "segment": {"id": "repeat_buyers", "label": "ë°˜ë³µ êµ¬ë§¤ ê³ ê°"},
  "nodes": [{"id": "product_detail", "label": "Product detail", "value": 620}],
  "links": [{"source": "product_detail", "target": "add_to_cart", "value": 310}],
  "summary": {"total_transitions": 1240, "edge_count": 5, "node_count": 6},
  "filters": {"start_date": "2025-10-15", "end_date": "2025-10-28", "limit": 25, "min_edge_count": 3}
}
```

ìˆ˜ë™ ê²€ì¦ ìˆœì„œ:
1. `uv run fastapi dev` (ë˜ëŠ” `uvicorn app.main:app --reload`) ë¡œ ë°±ì—”ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
2. `cd frontend && npm install && npm run dev` ë¡œ í”„ë¡ íŠ¸ë¥¼ ë„ì›ë‹ˆë‹¤.
3. UI ìƒë‹¨ì˜ **ê³ ê° í–‰ë™ ë„¤íŠ¸ì›Œí¬** íŒ¨ë„ì—ì„œ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë°”ê¾¸ê³ , ë‚ ì§œ/ì„ê³„ê°’ì„ ì¡°ì •í•´ ê·¸ë˜í”„ê°€ ìƒˆë¡œê³ ì¹¨ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
4. ë¸Œë¼ìš°ì € ê°œë°œì ë„êµ¬ì—ì„œ `/api/network/customer-flow` í˜¸ì¶œ payload/response ë¥¼ í™•ì¸í•˜ë©´ ë™ì¼í•œ nodes/links ë°ì´í„°ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
f:\codex\codex1\
â”œâ”€â”€ app/                           # FastAPI ë°±ì—”ë“œ
â”‚   â”œâ”€â”€ main.py                   # ì• í”Œë¦¬ì¼€ì´ì…˜ ì§„ì…ì 
â”‚   â”œâ”€â”€ config.py                 # í™˜ê²½ ì„¤ì • (Pydantic)
â”‚   â”œâ”€â”€ deps.py                   # ë¡œê¹… ì„¤ì •
â”‚   â”œâ”€â”€ guardrails.json           # ë³´ì•ˆ ì •ì±…
â”‚   â”‚
â”‚   â”œâ”€â”€ routers/                  # API ì—”ë“œí¬ì¸íŠ¸
â”‚   â”‚   â”œâ”€â”€ health.py             # /healthz, /readyz
â”‚   â”‚   â””â”€â”€ query.py              # /api/query, /api/query/stream
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                 # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ (12ë‹¨ê³„ íŒŒì´í”„ë¼ì¸)
â”‚   â”‚   â”œâ”€â”€ normalize.py          # í…ìŠ¤íŠ¸ ì •ê·œí™”
â”‚   â”‚   â”œâ”€â”€ context.py            # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ nlu.py                # ìì—°ì–´ ì´í•´ (í•˜ì´ë¸Œë¦¬ë“œ)
â”‚   â”‚   â”œâ”€â”€ planner.py            # ì¿¼ë¦¬ ê³„íš ìƒì„±
â”‚   â”‚   â”œâ”€â”€ sqlgen.py             # LLM ê¸°ë°˜ SQL ìƒì„± (ì‹ ê·œ)
â”‚   â”‚   â”œâ”€â”€ llm.py                # LLM SQL ìƒì„± (ë ˆê±°ì‹œ)
â”‚   â”‚   â”œâ”€â”€ prompt.py             # LLM í”„ë¡¬í”„íŠ¸ ë¹Œë”
â”‚   â”‚   â”œâ”€â”€ linking.py            # ìŠ¤í‚¤ë§ˆ ë§í‚¹ (í•˜ì´ë¸Œë¦¬ë“œ)
â”‚   â”‚   â”œâ”€â”€ guard.py              # SQL íŒŒì‹± (SQLGlot)
â”‚   â”‚   â”œâ”€â”€ validator.py          # ë³´ì•ˆ ê²€ì‚¬ ë° ë¦°íŠ¸
â”‚   â”‚   â”œâ”€â”€ validation.py         # 6ë‹¨ê³„ ê²€ì¦ íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â”œâ”€â”€ repair.py             # LLM ê¸°ë°˜ ì˜¤ë¥˜ ìˆ˜ì •
â”‚   â”‚   â”œâ”€â”€ executor.py           # BigQuery ì‹¤í–‰
â”‚   â”‚   â”œâ”€â”€ summarize.py          # ê²°ê³¼ ìš”ì•½
â”‚   â”‚   â””â”€â”€ templates.py          # í…œí”Œë¦¿ SQL
â”‚   â”‚
â”‚   â”œâ”€â”€ bq/                       # BigQuery í†µí•©
â”‚   â”‚   â””â”€â”€ connector.py          # BigQuery í´ë¼ì´ì–¸íŠ¸ ë˜í¼
â”‚   â”‚
â”‚   â”œâ”€â”€ schema/                   # ìŠ¤í‚¤ë§ˆ ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ catalog.py            # í…Œì´ë¸”/ì»¬ëŸ¼ ì¹´íƒˆë¡œê·¸ (ìºì‹±)
â”‚   â”‚   â””â”€â”€ aliases.yaml          # í•œì˜ ì»¬ëŸ¼ ë³„ì¹­ ë§¤í•‘
â”‚   â”‚
â”‚   â”œâ”€â”€ semantic/                 # ì‹œë§¨í‹± ëª¨ë¸ (í•µì‹¬!)
â”‚   â”‚   â”œâ”€â”€ semantic.yml          # ì—”í‹°í‹°/ì°¨ì›/ì¸¡ì •í•­ëª© ì •ì˜
â”‚   â”‚   â”œâ”€â”€ metrics_definitions.yaml  # ë©”íŠ¸ë¦­ ê³µì‹ ë° í•„í„°
â”‚   â”‚   â”œâ”€â”€ golden_queries.yaml   # Few-shot ì˜ˆì œ
â”‚   â”‚   â”œâ”€â”€ datasets.yaml         # í…Œì´ë¸”ëª… ì˜¤ë²„ë¼ì´ë“œ
â”‚   â”‚   â”œâ”€â”€ ga4_schema.yaml       # GA4 ìŠ¤í‚¤ë§ˆ ì •ì˜
â”‚   â”‚   â””â”€â”€ loader.py             # YAML ë¡œë”
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ timeparse.py          # ë‚ ì§œ/ì‹œê°„ ìœ í‹¸ë¦¬í‹°
â”‚
â”œâ”€â”€ frontend/                     # Vite + Vue3 í”„ë¡ íŠ¸ì—”ë“œ
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ vite.config.ts            # /api í”„ë¡ì‹œ ì„¤ì •
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.vue               # ë©”ì¸ ë ˆì´ì•„ì›ƒ
â”‚       â”œâ”€â”€ main.ts               # ì—”íŠ¸ë¦¬í¬ì¸íŠ¸
â”‚       â”œâ”€â”€ views/
â”‚       â”‚   â””â”€â”€ ChatView.vue      # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
â”‚       â”œâ”€â”€ components/
â”‚       â”‚   â”œâ”€â”€ ChatInput.vue     # ì…ë ¥ ì»´í¬ë„ŒíŠ¸
â”‚       â”‚   â”œâ”€â”€ ChatMessage.vue   # ë§ˆí¬ë‹¤ìš´ ë Œë”ë§ (KaTeX, Mermaid)
â”‚       â”‚   â””â”€â”€ ResultPanel.vue   # ê²°ê³¼ í…Œì´ë¸” (í˜ì´ì§€ë„¤ì´ì…˜, CSV)
â”‚       â””â”€â”€ store/
â”‚           â””â”€â”€ chat.ts           # ëŒ€í™” ìƒíƒœ ê´€ë¦¬
â”‚
â”œâ”€â”€ tests/                        # í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸
â”‚   â”œâ”€â”€ test_health.py
â”‚   â”œâ”€â”€ test_query_stub.py
â”‚   â””â”€â”€ test_stream_sse.py
â”‚
â”œâ”€â”€ scripts/                      # ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ stream_demo.py            # SSE ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸
â”‚
â”œâ”€â”€ docs/                         # ë¬¸ì„œ
â”‚   â””â”€â”€ validation_architecture.md  # ê²€ì¦ ì•„í‚¤í…ì²˜ ì„¤ëª…
â”‚
â”œâ”€â”€ logs/                         # ë¡œê·¸ íŒŒì¼ (ìë™ ìƒì„±)
â”‚   â””â”€â”€ app.log
â”‚
â”œâ”€â”€ pyproject.toml                # Python ì˜ì¡´ì„±
â”œâ”€â”€ .env.example                  # í™˜ê²½ë³€ìˆ˜ í…œí”Œë¦¿
â”œâ”€â”€ .env                          # í™˜ê²½ë³€ìˆ˜ (gitignore)
â”œâ”€â”€ backend_analysis_report.md    # ë°±ì—”ë“œ ë¶„ì„ ë³´ê³ ì„œ
â””â”€â”€ README.md                     # ì´ íŒŒì¼
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# .env íŒŒì¼ ìƒì„±
cp .env.example .env

# .env íŒŒì¼ í¸ì§‘ (í•„ìˆ˜)
# - GCP í”„ë¡œì íŠ¸ ì„¤ì •
# - LLM API í‚¤ ì„¤ì • (ìµœì†Œ 1ê°œ)
```

**.env ì˜ˆì‹œ**:
```bash
# í™˜ê²½
env=dev
gcp_project=your-gcp-project-id
bq_default_location=asia-northeast3

# LLM í”„ë¡œë°”ì´ë” (openai, claude, gemini ì¤‘ ì„ íƒ)
llm_provider=openai

# OpenAI ì„¤ì •
openai_api_key=sk-...
openai_model=gpt-4o-mini

# BigQuery ì„¤ì •
dry_run_only=true
maximum_bytes_billed=1000000000

# ë¡œê¹…
log_file_path=logs/app.log
log_rotation=daily
```

### 2. ë°±ì—”ë“œ ì‹¤í–‰

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -e .

# ì„œë²„ ì‹¤í–‰
uvicorn app.main:app --host 0.0.0.0 --port 8080 --reload
```

**ì„œë²„ ì‹¤í–‰ í™•ì¸**:
```bash
curl http://localhost:8080/healthz
# {"status":"ok"}
```

### 3. í”„ë¡ íŠ¸ì—”ë“œ ì‹¤í–‰ (ì„ íƒì )

```bash
cd frontend

# ì˜ì¡´ì„± ì„¤ì¹˜
npm install

# ê°œë°œ ì„œë²„ ì‹¤í–‰
npm run dev
# â†’ http://localhost:5173
```

### 4. í…ŒìŠ¤íŠ¸

```bash
# Python í…ŒìŠ¤íŠ¸
pytest -q

# SSE ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸
python scripts/stream_demo.py
```

---

## ğŸ“¡ API ì—”ë“œí¬ì¸íŠ¸

### Health Check

```bash
GET /healthz
GET /readyz
```

### Query (ë™ê¸°ì‹)

```bash
POST /api/query
Content-Type: application/json

{
  "q": "ì§€ë‚œ 7ì¼ ë””ë°”ì´ìŠ¤ë³„ ë°©ë¬¸ì ìˆ˜",
  "limit": 100,
  "dry_run": true,
  "use_llm": true,
  "llm_provider": "openai",
  "conversation_id": "session_123",
  "materialize": false
}
```

**ì‘ë‹µ**:
```json
{
  "sql": "SELECT device.category, COUNT(DISTINCT user_pseudo_id) AS users...",
  "dry_run": true,
  "rows": null,
  "metadata": {
    "validation_steps": [...],
    "total_bytes_processed": 75832225,
    "estimated_cost_usd": 0.000345,
    "linking": {...},
    "summary": "í–‰ ìˆ˜: 0 | ì˜ˆìƒë¹„ìš©: $0.000345"
  }
}
```

### Query Stream (SSE)

```bash
GET /api/query/stream?q=ì§€ë‚œ 7ì¼ ì£¼ë¬¸ ì¶”ì´&limit=10&dry_run=true
```

**SSE ì´ë²¤íŠ¸**:
```
event: normalize
data: {"text_len": 11, "meta": {"normalized": true}}

event: context
data: {"keys": []}

event: nlu
data: {"intent": "metric_over_time", "slots": {...}}

event: plan
data: {"intent": "metric_over_time", "metric": "orders", "grain": "day"}

event: sql
data: {"sql": "SELECT...", "source": "semantic_llm", "provider": "openai"}

event: linking
data: {"confidence": 0.9, "candidates": [...]}

event: validated
data: {"ok": true}

event: check
data: {"name": "lint", "ok": true, ...}

event: check
data: {"name": "dry_run", "ok": true, "meta": {"total_bytes_processed": 75832225}}

event: result
data: {"sql": "...", "dry_run": true, "rows": null, "metadata": {...}}
```

---

## ğŸ§  12ë‹¨ê³„ NL2SQL íŒŒì´í”„ë¼ì¸

```
ìì—°ì–´ ì§ˆë¬¸
    â†“
[1] Normalize - í…ìŠ¤íŠ¸ ì •ê·œí™” ë° ë™ì˜ì–´ ì¹˜í™˜
    â†“
[2] Context - ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ
    â†“
[3] NLU - ì˜ë„ ë° ìŠ¬ë¡¯ ì¶”ì¶œ (í•˜ì´ë¸Œë¦¬ë“œ: í‚¤ì›Œë“œ + LLM)
    â†“
[4] Planner - ì‹¤í–‰ ê³„íš ìƒì„± (ì‹œë§¨í‹± ëª¨ë¸ ê¸°ë°˜ ê²€ì¦)
    â†“
[5] SQL Generation - LLM ê¸°ë°˜ ë™ì  SQL ìƒì„±
    â”‚   â”œâ”€ GA4 í…Œì´ë¸” ì„œí”½ìŠ¤ ìë™ ì²˜ë¦¬
    â”‚   â”œâ”€ ì‹œë§¨í‹± ëª¨ë¸ ë©”íŠ¸ë¦­ ì •ì˜ í™œìš©
    â”‚   â””â”€ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë°˜ì˜
    â†“
[6] Schema Linking - ìŠ¤í‚¤ë§ˆ ìš”ì†Œ ë§¤ì¹­ (í•˜ì´ë¸Œë¦¬ë“œ: í† í° + LLM)
    â†“
[7] Guard - SQL íŒŒì‹± (SQLGlot) ë° ê°€ë“œë ˆì¼
    â†“
[8] Validation - 6ë‹¨ê³„ ê²€ì¦ íŒŒì´í”„ë¼ì¸
    â†“
[9] Repair - LLM ê¸°ë°˜ ì˜¤ë¥˜ ìë™ ìˆ˜ì • (ì„ íƒì )
    â†“
[10] Execute - BigQuery ì‹¤í–‰ (Dry Run / Full / Materialize)
    â†“
[11] Summarize - ê²°ê³¼ ìš”ì•½ (ê·œì¹™ ê¸°ë°˜ + LLM)
    â†“
[12] Response - í´ë¼ì´ì–¸íŠ¸ì— ì‘ë‹µ ë°˜í™˜
```

---

## ğŸ¯ ì‹œë§¨í‹± ëª¨ë¸

### semantic.yml - ì—”í‹°í‹° ë° ì°¨ì› ì •ì˜

```yaml
entities:
  - name: event
    grain: event_id
    table: `project.dataset.events_*`
    dimensions:
      - name: event_date
      - name: event_name
      - name: user_pseudo_id
    measures:
      - name: events
        expr: COUNT(*)

  - name: session
    grain: session_id
    dimensions:
      - name: device_category  # â†’ device.category (GA4)
      - name: source_medium    # â†’ traffic_source.medium
    measures:
      - name: sessions
        expr: COUNT(DISTINCT session_id)

# NLU í‚¤ì›Œë“œ (í•˜ì´ë¸Œë¦¬ë“œ ë§¤ì¹­)
nlu_keywords:
  intents:
    metric_over_time: ['ì¶”ì´', 'trend', 'ë³€í™”']
  metrics:
    orders: ['ì£¼ë¬¸', 'orders', 'êµ¬ë§¤']
    users: ['ì‚¬ìš©ì', 'ë°©ë¬¸ì', 'users']

# Planner ì„¤ì •
planner_config:
  valid_intents: [metric, metric_over_time, comparison, aggregation]
  defaults:
    metric: orders
    grain: day

# GA4 ìŠ¤í‚¤ë§ˆ (ë„¤ìŠ¤í‹°ë“œ í•„ë“œ)
ga4_schema:
  nested_fields:
    device:
      - category: "device.category"
      - operating_system: "device.operating_system"
    geo:
      - country: "geo.country"
      - city: "geo.city"

common_dimensions:
  ë””ë°”ì´ìŠ¤ë³„: "device.category"
  êµ­ê°€ë³„: "geo.country"
```

### metrics_definitions.yaml - ë©”íŠ¸ë¦­ ê³µì‹

```yaml
metrics:
  - name: gmv
    description: ì´ ê±°ë˜ì•¡
    expr: SUM(ecommerce.purchase_revenue)
    default_filters:
      - event_name = 'purchase'

  - name: orders
    description: ì£¼ë¬¸ ê±´ìˆ˜
    expr: COUNT(DISTINCT ecommerce.transaction_id)
    default_filters:
      - event_name = 'purchase'
```

### golden_queries.yaml - Few-shot ì˜ˆì œ

```yaml
queries:
  - nl: "ì§€ë‚œ 7ì¼ ì£¼ë¬¸ ì¶”ì´"
    intent: metric_over_time
    slots:
      metric: orders
      time_window: {days: 7}
      grain: day

  - nl: "ë””ë°”ì´ìŠ¤ë³„ ë°©ë¬¸ì ìˆ˜"
    intent: aggregation
    slots:
      metric: users
      group_by: [device_category]
```

---

## ğŸ”§ ì„¤ì •

### LLM í”„ë¡œë°”ì´ë” ì„¤ì •

```bash
# .env íŒŒì¼

# OpenAI (ê¶Œì¥)
llm_provider=openai
openai_api_key=sk-...
openai_model=gpt-4o-mini

# ë˜ëŠ” Claude
llm_provider=claude
anthropic_api_key=sk-ant-...
anthropic_model=claude-3-5-sonnet-20240620

# ë˜ëŠ” Gemini
llm_provider=gemini
gemini_api_key=AIza...
gemini_model=gemini-1.5-flash

# LLM íŒŒë¼ë¯¸í„°
llm_temperature=0.1
llm_max_tokens=2048
llm_enable_repair=true
llm_enable_result_summary=false
```

### BigQuery ì„¤ì •

```bash
# GCP í”„ë¡œì íŠ¸
gcp_project=your-project-id
bq_default_location=asia-northeast3

# ë¹„ìš© ì œí•œ (ë°”ì´íŠ¸ ë‹¨ìœ„)
maximum_bytes_billed=10000000000  # 10GB

# Dry Run ì „ìš© ëª¨ë“œ (ì•ˆì „)
dry_run_only=true

# ê°€ê²© ì„¤ì • (TBë‹¹ USD)
price_per_tb_usd=5.0
```

### ë¡œê¹… ì„¤ì •

```bash
# ë¡œê·¸ íŒŒì¼
log_file_path=logs/app.log

# ë¡œí…Œì´ì…˜ ë°©ì‹
log_rotation=daily  # ë˜ëŠ” size

# ë¡œê·¸ ë ˆë²¨
log_level=INFO

# UTC ì‹œê°„ ì‚¬ìš©
log_utc=false
```

---

## ğŸ’» ì‚¬ìš© ì˜ˆì‹œ

### cURL

```bash
# ê°„ë‹¨í•œ ì§ˆë¬¸ (í‚¤ì›Œë“œ ë§¤ì¹­)
curl -X POST http://localhost:8080/api/query \
  -H "Content-Type: application/json" \
  -d '{"q": "ì§€ë‚œ 7ì¼ ì£¼ë¬¸ ì¶”ì´", "dry_run": true}'

# ë³µì¡í•œ ì§ˆë¬¸ (LLM ì‚¬ìš©)
curl -X POST http://localhost:8080/api/query \
  -H "Content-Type: application/json" \
  -d '{
    "q": "ì‘ë…„ ë™ê¸° ëŒ€ë¹„ ì˜¬í•´ ëª¨ë°”ì¼ ê³ ê°ì˜ í‰ê·  êµ¬ë§¤ì•¡ ì¦ê°€ìœ¨",
    "use_llm": true,
    "llm_provider": "openai",
    "dry_run": false
  }'

# SSE ìŠ¤íŠ¸ë¦¬ë°
curl "http://localhost:8080/api/query/stream?q=ì§€ë‚œ+7ì¼+ì£¼ë¬¸+ì¶”ì´&dry_run=true"
```

### Python

```python
import httpx

# ë™ê¸°ì‹ ì¿¼ë¦¬
response = httpx.post("http://localhost:8080/api/query", json={
    "q": "ë””ë°”ì´ìŠ¤ë³„ ì‹œê°„ëŒ€ë³„ ë°©ë¬¸ì ìˆ˜",
    "limit": 100,
    "dry_run": True
})

result = response.json()
print(result["sql"])
print(result["metadata"]["estimated_cost_usd"])

# SSE ìŠ¤íŠ¸ë¦¬ë°
async with httpx.AsyncClient() as client:
    async with client.stream(
        "GET",
        "http://localhost:8080/api/query/stream",
        params={"q": "ì§€ë‚œ 7ì¼ ì£¼ë¬¸ ì¶”ì´", "dry_run": "true"}
    ) as response:
        async for line in response.aiter_lines():
            print(line)
```

---

## ğŸ“Š ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨

### ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Vue3 Frontend  â”‚
â”‚   (ChatGPT UI)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ REST/SSE
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FastAPI Backend                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  12ë‹¨ê³„ NL2SQL íŒŒì´í”„ë¼ì¸            â”‚ â”‚
â”‚  â”‚  1. Normalize â†’ 2. Context â†’       â”‚ â”‚
â”‚  â”‚  3. NLU â†’ 4. Planner â†’             â”‚ â”‚
â”‚  â”‚  5. SQL Gen â†’ 6. Linking â†’         â”‚ â”‚
â”‚  â”‚  7. Guard â†’ 8. Validation â†’        â”‚ â”‚
â”‚  â”‚  9. Repair â†’ 10. Execute â†’         â”‚ â”‚
â”‚  â”‚  11. Summarize â†’ 12. Response      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ì‹œë§¨í‹± ëª¨ë¸ (YAML)                  â”‚ â”‚
â”‚  â”‚  - ì—”í‹°í‹°/ì°¨ì›/ì¸¡ì •í•­ëª©              â”‚ â”‚
â”‚  â”‚  - ë©”íŠ¸ë¦­ ê³µì‹ ë° í•„í„°               â”‚ â”‚
â”‚  â”‚  - Few-shot ì˜ˆì œ                    â”‚ â”‚
â”‚  â”‚  - GA4 ìŠ¤í‚¤ë§ˆ                        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                      â”‚
       â†“                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM APIs    â”‚      â”‚  BigQuery    â”‚
â”‚  - OpenAI    â”‚      â”‚  - Events    â”‚
â”‚  - Claude    â”‚      â”‚  - Orders    â”‚
â”‚  - Gemini    â”‚      â”‚  - Sessions  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¨ ì£¼ìš” ëª¨ë“ˆ ì„¤ëª…

### ë°±ì—”ë“œ ì„œë¹„ìŠ¤

| ëª¨ë“ˆ | ì—­í•  | í•˜ì´ë¸Œë¦¬ë“œ | íŒŒì¼ |
|------|------|----------|------|
| **normalize** | í…ìŠ¤íŠ¸ ì •ê·œí™”, ë™ì˜ì–´ ì¹˜í™˜ | - | normalize.py |
| **context** | ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ | - | context.py |
| **nlu** | ì˜ë„/ìŠ¬ë¡¯ ì¶”ì¶œ | âœ… í‚¤ì›Œë“œ + LLM | nlu.py |
| **planner** | ì¿¼ë¦¬ ê³„íš, ê²€ì¦ | - | planner.py |
| **sqlgen** | SQL ìƒì„± (ì‹ ê·œ) | LLM ê¸°ë°˜ | sqlgen.py |
| **linking** | ìŠ¤í‚¤ë§ˆ ë§¤ì¹­ | âœ… í† í° + LLM | linking.py |
| **guard** | SQL íŒŒì‹±, ê°€ë“œë ˆì¼ | - | guard.py |
| **validator** | ë³´ì•ˆ/í’ˆì§ˆ ê²€ì‚¬ | - | validator.py |
| **validation** | 6ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ | - | validation.py |
| **executor** | BigQuery ì‹¤í–‰ | - | executor.py |

### ì‹œë§¨í‹± ë ˆì´ì–´

| íŒŒì¼ | ì—­í•  |
|------|------|
| semantic.yml | ì—”í‹°í‹°, ì°¨ì›, ì¸¡ì •í•­ëª©, NLU í‚¤ì›Œë“œ, GA4 ìŠ¤í‚¤ë§ˆ |
| metrics_definitions.yaml | ë©”íŠ¸ë¦­ ê³µì‹ ë° ê¸°ë³¸ í•„í„° |
| golden_queries.yaml | Few-shot í•™ìŠµ ì˜ˆì œ |
| datasets.yaml | í…Œì´ë¸”ëª… ì˜¤ë²„ë¼ì´ë“œ |
| ga4_schema.yaml | GA4 ë„¤ìŠ¤í‹°ë“œ í•„ë“œ ìƒì„¸ ì •ì˜ |
| aliases.yaml | í•œì˜ ì»¬ëŸ¼ ë³„ì¹­ ë§¤í•‘ |

---

## ğŸ” GA4 BigQuery Export ì§€ì›

### ë„¤ìŠ¤í‹°ë“œ í•„ë“œ ìë™ ì²˜ë¦¬

**ì§ˆë¬¸**: "ë””ë°”ì´ìŠ¤ë³„ êµ­ê°€ë³„ ë°©ë¬¸ì ìˆ˜"

**ìƒì„± SQL**:
```sql
SELECT
  device.category AS device_category,  -- ë„¤ìŠ¤í‹°ë“œ í•„ë“œ!
  geo.country AS country,               -- ë„¤ìŠ¤í‹°ë“œ í•„ë“œ!
  COUNT(DISTINCT user_pseudo_id) AS users
FROM `project.dataset.events_*` AS e
WHERE _TABLE_SUFFIX BETWEEN '20251031' AND '20251107'
GROUP BY device.category, geo.country
ORDER BY users DESC
LIMIT 100
```

### í…Œì´ë¸” ì„œí”½ìŠ¤ ìë™ ê³„ì‚°

| ì§ˆë¬¸ | _TABLE_SUFFIX ì¡°ê±´ |
|------|-------------------|
| "ì–´ì œ" | `= '20251106'` |
| "ì§€ë‚œ 7ì¼" | `BETWEEN '20251031' AND '20251107'` |
| "ìµœê·¼ 30ì¼" | `BETWEEN '20251008' AND '20251107'` |

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸
pytest

# íŠ¹ì • í…ŒìŠ¤íŠ¸
pytest tests/test_query_stub.py -v

# ì»¤ë²„ë¦¬ì§€
pytest --cov=app --cov-report=html
```

---

## ğŸ“– ë¬¸ì„œ

- [backend_analysis_report.md](backend_analysis_report.md) - ë°±ì—”ë“œ ì•„í‚¤í…ì²˜ ìƒì„¸ ë¶„ì„
- [docs/validation_architecture.md](docs/validation_architecture.md) - ê²€ì¦ íŒŒì´í”„ë¼ì¸ ì„¤ëª…
- [app/semantic/ga4_schema.yaml](app/semantic/ga4_schema.yaml) - GA4 ìŠ¤í‚¤ë§ˆ ë ˆí¼ëŸ°ìŠ¤

---

## ğŸ› ï¸ ê°œë°œ ê°€ì´ë“œ

### ìƒˆë¡œìš´ ë©”íŠ¸ë¦­ ì¶”ê°€

```yaml
# semantic.yml
metrics:
  - name: revenue
    expr: SUM(ecommerce.purchase_revenue_in_usd)
    default_filters:
      - event_name = 'purchase'
```

â†’ ì½”ë“œ ë³€ê²½ ì—†ì´ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥!

### ìƒˆë¡œìš´ NLU í‚¤ì›Œë“œ ì¶”ê°€

```yaml
# semantic.yml
nlu_keywords:
  metrics:
    revenue:
      - 'ìˆ˜ìµ'
      - 'profit'
      - 'ì´ìµ'
```

â†’ ì„œë²„ ì¬ì‹œì‘ë§Œìœ¼ë¡œ ì ìš©!

### ì»¤ìŠ¤í…€ LLM í”„ë¡¬í”„íŠ¸

```python
# .env
llm_system_prompt=You are a BigQuery SQL expert specializing in GA4 analytics.
```

---

## ğŸš¨ ë¬¸ì œ í•´ê²°

### OpenAI API ì˜¤ë¥˜

**ì˜¤ë¥˜**: `Unsupported parameter: 'max_tokens'`

**í•´ê²°**: gpt-4o ëª¨ë¸ì€ `max_completion_tokens` ì‚¬ìš© (ìë™ ì²˜ë¦¬ë¨)

### BigQuery ì—°ê²° ì˜¤ë¥˜

**ì˜¤ë¥˜**: `BigQuery client not installed`

**í•´ê²°**:
```bash
pip install google-cloud-bigquery
```

### ê°€ë“œë ˆì¼ ìœ„ë°˜

**ì˜¤ë¥˜**: `GuardrailViolation: query violates guardrail policy`

**ì›ì¸**: DELETE, UPDATE, INSERT, DROP, SELECT * ì‚¬ìš©

**í•´ê²°**: `guardrails.json` ì •ì±… í™•ì¸ ë° SQL ìˆ˜ì •

---

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### ìºì‹± ì „ëµ
- **ì‹œë§¨í‹± ëª¨ë¸**: ë©”ëª¨ë¦¬ ìºì‹œ (ì¬ë¡œë“œ ë¶ˆí•„ìš”)
- **ì¹´íƒˆë¡œê·¸**: TTL 30ë¶„
- **BigQuery ê²°ê³¼**: êµ¬ì²´í™”(materialize) ì˜µì…˜

### ë¹„ìš© ì ˆê°
- **Dry Run ìš°ì„ **: ë¬´ë£Œ êµ¬ë¬¸ ê²€ì¦
- **Early Exit**: ê²€ì¦ ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨
- **LIMIT ì‚¬ìš©**: Schema(0), Canary(100)

### í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ
- **ê°„ë‹¨í•œ ì§ˆë¬¸**: í‚¤ì›Œë“œ ë§¤ì¹­ (ë¬´ë£Œ, ë¹ ë¦„)
- **ë³µì¡í•œ ì§ˆë¬¸**: LLM í˜¸ì¶œ (ìœ ë£Œ, ì •í™•)

---

## ğŸ¤ ê¸°ì—¬ ê°€ì´ë“œ

### ë¸Œëœì¹˜ ì „ëµ
- `main`: í”„ë¡œë•ì…˜
- `develop`: ê°œë°œ
- `feature/*`: ê¸°ëŠ¥ ê°œë°œ

### ì»¤ë°‹ ë©”ì‹œì§€
```
feat: ìƒˆë¡œìš´ ë©”íŠ¸ë¦­ ì¶”ê°€
fix: GA4 ë„¤ìŠ¤í‹°ë“œ í•„ë“œ ì˜¤ë¥˜ ìˆ˜ì •
docs: README ì—…ë°ì´íŠ¸
refactor: SQL ìƒì„± ë¡œì§ ê°œì„ 
```

---

## ğŸ“ ë¼ì´ì„ ìŠ¤

MIT License

---

## ğŸ‘¥ ì‘ì„±ì

AI-powered NL2SQL Platform

---

## ğŸ”— ì°¸ê³  ìë£Œ

- [FastAPI ê³µì‹ ë¬¸ì„œ](https://fastapi.tiangolo.com/)
- [BigQuery í‘œì¤€ SQL](https://cloud.google.com/bigquery/docs/reference/standard-sql/query-syntax)
- [GA4 BigQuery Export ìŠ¤í‚¤ë§ˆ](https://support.google.com/analytics/answer/7029846)
- [SQLGlot ë¬¸ì„œ](https://sqlglot.com/)

---

## ğŸ¯ ë¡œë“œë§µ

### v1.0 (í˜„ì¬)
- âœ… 12ë‹¨ê³„ NL2SQL íŒŒì´í”„ë¼ì¸
- âœ… ë‹¤ì¤‘ LLM ì§€ì›
- âœ… GA4 ë„¤ìŠ¤í‹°ë“œ í•„ë“œ ì²˜ë¦¬
- âœ… í•˜ì´ë¸Œë¦¬ë“œ ì•„í‚¤í…ì²˜

### v1.1 (ì˜ˆì •)
- â³ ë‹¤ì¤‘ í…Œì´ë¸” JOIN ìë™ ìƒì„±
- â³ ì„ë² ë”© ê¸°ë°˜ ìŠ¤í‚¤ë§ˆ ë§í‚¹
- â³ Redis ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ ì €ì¥
- â³ ì¿¼ë¦¬ ìºì‹±

### v2.0 (ì¥ê¸°)
- â³ ìë™ ì¿¼ë¦¬ ìµœì í™”
- â³ ì‹œê°í™” ìë™ ìƒì„±
- â³ ë‹¤êµ­ì–´ ì§€ì› í™•ëŒ€
- â³ ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°

---

## ğŸ“ ìƒì„¸ Sequence Diagram

### ì „ì²´ ìì—°ì–´ ì§ˆì˜ ì²˜ë¦¬ íë¦„ (í•¨ìˆ˜ ë ˆë²¨)

```mermaid
sequenceDiagram
    autonumber
    participant User
    participant ChatView as Frontend<br/>ChatView.vue
    participant API as FastAPI<br/>query.py

    box Services Layer
    participant NX as normalize.py<br/>normalize()
    participant CTX as context.py<br/>get_context()
    participant NLU as nlu.py<br/>extract()
    participant PL as planner.py<br/>make_plan()
    participant SG as sqlgen.py<br/>generate()
    participant LINKING as linking.py<br/>schema_link()
    participant GRD as guard.py<br/>parse_sql()
    participant VAL as validator.py<br/>ensure_safe()
    participant PIPE as validation.py<br/>run_pipeline()
    participant EXE as executor.py<br/>run()
    participant SUM as summarize.py<br/>summarize()
    end

    participant LLM as LLM API<br/>OpenAI/Claude/Gemini
    participant BQ as BigQuery<br/>API

    User->>ChatView: ì§ˆë¬¸ ì…ë ¥: "ë””ë°”ì´ìŠ¤ë³„ ì‹œê°„ëŒ€ë³„ ë°©ë¬¸ì ìˆ˜"
    ChatView->>API: POST /api/query/stream

    Note over API: 1. í…ìŠ¤íŠ¸ ì •ê·œí™”
    API->>NX: normalize(q)
    NX->>NX: ê³µë°± ì •ë¦¬, ë™ì˜ì–´ ì¹˜í™˜
    NX-->>API: (normalized_text, meta)
    API-->>ChatView: event: normalize

    Note over API: 2. ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ë¡œë“œ
    API->>CTX: get_context(conversation_id)
    CTX-->>API: {last_sql, last_plan}
    API-->>ChatView: event: context

    Note over API: 3. ìì—°ì–´ ì´í•´ (í•˜ì´ë¸Œë¦¬ë“œ)
    API->>NLU: extract(normalized_text, use_llm=True)
    NLU->>NLU: _extract_keyword_based(q)
    NLU->>NLU: _calculate_confidence(intent, slots)

    alt confidence < 0.7
        NLU->>LLM: _call_openai(prompt)<br/>"ì˜ë„ì™€ ìŠ¬ë¡¯ ì¶”ì¶œ"
        LLM-->>NLU: {intent, slots} JSON
    end

    NLU-->>API: (intent, slots)
    API-->>ChatView: event: nlu

    Note over API: 4. ì¿¼ë¦¬ ê³„íš ìƒì„±
    API->>PL: make_plan(intent, slots, validate=False)
    PL->>PL: _load_semantic_config()
    PL->>PL: ê¸°ë³¸ê°’ ì ìš© (metric, grain)
    PL-->>API: plan {intent, metric, grain, slots}
    API-->>ChatView: event: plan

    Note over API: 5. SQL ìƒì„± (LLM ê¸°ë°˜)
    API->>SG: generate(plan, question, limit, llm_provider)
    SG->>SG: _determine_table_suffix()<br/>ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
    SG->>SG: _analyze_required_tables()<br/>í…Œì´ë¸” ë¶„ì„
    SG->>SG: _build_sql_generation_prompt()<br/>ì‹œë§¨í‹± ëª¨ë¸ + GA4 ìŠ¤í‚¤ë§ˆ
    SG->>LLM: _call_openai_for_sql(prompt)<br/>"BigQuery SQL ìƒì„±"
    LLM-->>SG: SQL ë¬¸ìì—´
    SG->>SG: _post_process_sql()<br/>ì½”ë“œ ë¸”ë¡ ì œê±°, LIMIT ì¶”ê°€
    SG-->>API: SQL
    API-->>ChatView: event: sql

    Note over API: 6. ìŠ¤í‚¤ë§ˆ ë§í‚¹ (í•˜ì´ë¸Œë¦¬ë“œ)
    API->>LINKING: match schema elements
    LINKING->>LINKING: token based matching<br/>í† í° + ë³„ì¹­ + ë™ì˜ì–´ ë§¤ì¹­

    alt confidence < 0.6
        LINKING->>LLM: llm based matching<br/>"ìŠ¤í‚¤ë§ˆ ìš”ì†Œ ë§¤ì¹­"
        LLM-->>LINKING: {candidates, confidence} JSON
    end

    LINKING-->>API: {candidates, confidence, method}
    API-->>ChatView: event: linking

    Note over API: 7. ê°€ë“œë ˆì¼ ê²€ì‚¬
    API->>GRD: parse_sql(sql)
    GRD->>GRD: sqlglot.parse_one(sql, "bigquery")
    GRD-->>API: AST or None

    API->>VAL: ensure_safe(sql)
    VAL->>VAL: _load_policy()<br/>guardrails.json ë¡œë“œ
    VAL->>VAL: ìœ„í—˜ í‚¤ì›Œë“œ ê²€ì‚¬<br/>(DELETE, UPDATE, DROP ë“±)
    VAL-->>API: ok or GuardrailViolation
    API-->>ChatView: event: validated {ok: true}

    Note over API: 8. ê²€ì¦ íŒŒì´í”„ë¼ì¸ (6ë‹¨ê³„)
    API->>PIPE: run_pipeline(sql, plan, logger)

    rect rgb(240, 248, 255)
    Note over PIPE: 8-1. Lint ê²€ì‚¬
    PIPE->>VAL: lint(sql)
    VAL->>VAL: SELECT * ê²€ì‚¬
    VAL->>VAL: ì‹œê°„ í•„í„° ê²€ì‚¬
    VAL-->>PIPE: StepResult(lint, ok, issues)
    PIPE-->>ChatView: event: check {name: "lint"}
    end

    rect rgb(240, 255, 240)
    Note over PIPE: 8-2. Dry Run
    PIPE->>BQ: run_query(sql, dry_run=True)
    BQ-->>PIPE: total_bytes_processed
    PIPE-->>ChatView: event: check {name: "dry_run", meta: {bytes}}
    end

    rect rgb(255, 250, 240)
    Note over PIPE: 8-3. Explain (ì„ íƒì )
    PIPE->>BQ: run_query("EXPLAIN " + sql)
    BQ-->>PIPE: execution plan or error
    PIPE-->>ChatView: event: check {name: "explain"}
    end

    rect rgb(255, 240, 245)
    Note over PIPE: 8-4. Schema ì¶”ì¶œ
    PIPE->>BQ: run_query("SELECT * FROM (...) LIMIT 0")
    BQ-->>PIPE: schema [name, type, mode]
    PIPE-->>ChatView: event: check {name: "schema"}
    end

    rect rgb(248, 248, 255)
    Note over PIPE: 8-5. Canary ì‹¤í–‰
    PIPE->>BQ: run_query("SELECT * FROM (...) LIMIT 100")
    BQ-->>PIPE: sample rows
    PIPE-->>ChatView: event: check {name: "canary"}
    end

    rect rgb(245, 255, 250)
    Note over PIPE: 8-6. Domain Assertions
    PIPE->>PIPE: domain_assertions(sql, plan)
    PIPE->>PIPE: ë©”íŠ¸ë¦­ í•„í„° ê²€ì¦
    PIPE->>PIPE: GROUP BY ê²€ì¦
    PIPE->>PIPE: ì‹œê°„ ë²„í‚·íŒ… ê²€ì¦
    PIPE-->>ChatView: event: check {name: "assertions"}
    end

    PIPE-->>API: ValidationReport {steps, sql, schema}

    Note over API: 9. ìµœì¢… ì‹¤í–‰

    alt dry_run == true
        API->>EXE: run(sql, dry_run=True)
        EXE->>BQ: dry_run query
        BQ-->>EXE: {bytes, cost, job_id}
        EXE-->>API: QueryResult {rows: null, meta}
    else materialize == true
        API->>EXE: materialize(sql)
        EXE->>BQ: CREATE TABLE ... AS SELECT ...
        BQ-->>EXE: destination_table
        EXE-->>API: QueryResult {rows: null, meta}
    else full execute
        API->>EXE: run(sql, dry_run=False)
        EXE->>BQ: execute query
        BQ-->>EXE: rows []
        EXE-->>API: QueryResult {rows, meta}
    end

    Note over API: 10. ê²°ê³¼ ìš”ì•½
    API->>SUM: summarize(rows, meta)
    SUM-->>API: summary_text

    opt llm_enable_result_summary == true
        API->>SUM: summarize_llm(question, sql, meta)
        SUM->>LLM: "ìì—°ì–´ ìš”ì•½ ìƒì„±"
        LLM-->>SUM: nl_summary
        SUM-->>API: nl_summary
    end

    Note over API: 11. ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
    API->>CTX: update_context(conv_id, {last_sql, last_plan})
    CTX-->>API: ok

    Note over API: 12. ì‘ë‹µ ë°˜í™˜
    API-->>ChatView: event: result<br/>{sql, dry_run, rows, metadata}
    ChatView->>ChatView: ê²°ê³¼ ë Œë”ë§<br/>ResultPanel.vue
    ChatView-->>User: SQL + í…Œì´ë¸” í‘œì‹œ

    Note over User,BQ: ì „ì²´ ì²˜ë¦¬ ì‹œê°„: 3-8ì´ˆ<br/>ë¹„ìš©: $0.0001 ~ $1.00 (ì¿¼ë¦¬ í¬ê¸°ì— ë”°ë¼)
```

### í•¨ìˆ˜ í˜¸ì¶œ ì²´ì¸ (ìƒì„¸)

```mermaid
sequenceDiagram
    autonumber
    participant Q as query.py::query_stream()

    box normalize.py
    participant N1 as normalize()
    end

    box context.py
    participant C1 as get_context()
    participant C2 as update_context()
    end

    box nlu.py
    participant NLU1 as extract()
    participant NLU2 as _extract_keyword_based()
    participant NLU3 as _calculate_confidence()
    participant NLU4 as _extract_llm_based()
    participant NLU5 as _call_openai()
    end

    box planner.py
    participant P1 as make_plan()
    participant P2 as _load_semantic_config()
    participant P3 as _validate_intent()
    participant P4 as _validate_metric()
    end

    box sqlgen.py
    participant S1 as generate()
    participant S2 as _determine_table_suffix()
    participant S3 as _analyze_required_tables()
    participant S4 as _build_sql_generation_prompt()
    participant S5 as _format_ga4_schema_for_prompt()
    participant S6 as _call_llm_for_sql()
    participant S7 as _call_openai_for_sql()
    participant S8 as _post_process_sql()
    end

    box linking.py
    participant L1 as schema_link()
    participant L2 as _schema_link_token_based()
    participant L3 as _schema_link_llm_based()
    end

    box validator.py
    participant V1 as ensure_safe()
    participant V2 as lint()
    participant V3 as _load_policy()
    end

    box validation.py
    participant VP1 as run_pipeline()
    participant VP2 as lint_sql()
    participant VP3 as dry_run()
    participant VP4 as schema()
    participant VP5 as canary()
    participant VP6 as domain_assertions()
    end

    box executor.py
    participant E1 as run()
    end

    participant BQ as BigQuery API

    Q->>N1: normalize(q)
    N1-->>Q: (text, meta)

    Q->>C1: get_context(conv_id)
    C1-->>Q: context dict

    Q->>NLU1: extract(text, use_llm=True)
    NLU1->>NLU2: _extract_keyword_based(q)
    NLU2-->>NLU1: (intent, slots)
    NLU1->>NLU3: _calculate_confidence(q, intent, slots)
    NLU3-->>NLU1: confidence

    alt confidence < 0.7
        NLU1->>NLU4: _extract_llm_based(q)
        NLU4->>NLU5: _call_openai(prompt)
        NLU5-->>NLU4: JSON response
        NLU4-->>NLU1: (llm_intent, llm_slots)
    end

    NLU1-->>Q: (intent, slots)

    Q->>P1: make_plan(intent, slots, validate=False)
    P1->>P2: _load_semantic_config()
    P2-->>P1: config dict

    opt validate == True
        P1->>P3: _validate_intent(intent, config)
        P1->>P4: _validate_metric(metric, config)
    end

    P1-->>Q: plan dict

    Q->>S1: generate(plan, question, limit, llm_provider)
    S1->>S2: _determine_table_suffix(plan, question, context)
    S2-->>S1: {use_wildcard, start_date, end_date, suffix_condition}

    S1->>S3: _analyze_required_tables(plan, semantic_model)
    S3-->>S1: [{entity, table, alias, is_primary}]

    S1->>S4: _build_sql_generation_prompt(...)
    S4->>S5: _format_ga4_schema_for_prompt(semantic_model)
    S5-->>S4: GA4 schema info
    S4-->>S1: complete prompt

    S1->>S6: _call_llm_for_sql(prompt, provider)
    S6->>S7: _call_openai_for_sql(prompt)
    S7->>BQ: OpenAI API call
    BQ-->>S7: SQL text
    S7-->>S6: SQL
    S6-->>S1: SQL

    S1->>S8: _post_process_sql(sql, limit)
    S8-->>S1: cleaned SQL
    S1-->>Q: final SQL

    Q->>L1: match schema
    L1->>L2: token based
    L2-->>L1: results

    alt confidence < 0.6
        L1->>L3: llm based
        L3->>BQ: LLM API call
        BQ-->>L3: results
        L3-->>L1: LLM result
    end

    L1-->>Q: final results

    Q->>V1: ensure_safe(sql)
    V1->>V3: _load_policy()
    V3-->>V1: guardrails policy
    V1->>V1: í‚¤ì›Œë“œ ê²€ì‚¬ (DELETE, DROP ë“±)
    V1-->>Q: ok or exception

    Q->>VP1: run_pipeline(sql, plan, logger)

    VP1->>VP2: lint_sql(sql)
    VP2->>V2: lint(sql)
    V2-->>VP2: issues []
    VP2-->>VP1: StepResult(lint)

    VP1->>VP3: dry_run(sql)
    VP3->>BQ: connector.run_query(sql, dry_run=True)
    BQ-->>VP3: job {total_bytes_processed}
    VP3-->>VP1: StepResult(dry_run)

    VP1->>VP4: schema(sql)
    VP4->>BQ: SELECT * FROM (...) LIMIT 0
    BQ-->>VP4: schema [{name, type, mode}]
    VP4-->>VP1: StepResult(schema)

    VP1->>VP5: canary(sql)
    VP5->>BQ: SELECT * FROM (...) LIMIT 100
    BQ-->>VP5: rows []
    VP5-->>VP1: StepResult(canary)

    VP1->>VP6: domain_assertions(sql, plan)
    VP6->>VP6: ë©”íŠ¸ë¦­ í•„í„° ê²€ì¦
    VP6->>VP6: GROUP BY ê²€ì¦
    VP6->>VP6: ì‹œê°„ ë²„í‚·íŒ… ê²€ì¦
    VP6-->>VP1: StepResult(assertions)

    VP1-->>Q: ValidationReport {steps, sql, schema}

    Q->>E1: run(sql, dry_run)
    E1->>BQ: execute query or dry_run
    BQ-->>E1: rows + metadata
    E1-->>Q: QueryResult {rows, meta}

    Q->>SUM: summarize(rows, meta)
    SUM-->>Q: summary text

    Q->>C2: update_context(conv_id, {last_sql, last_plan})
    C2-->>Q: ok

    Q-->>ChatView: event: result {sql, rows, metadata}
    ChatView-->>User: ê²°ê³¼ í…Œì´ë¸” í‘œì‹œ

    Note over User,BQ: ê° ë‹¨ê³„ë³„ ë¡œê·¸: ì‹œê°„ : íŒŒì¼ : í•¨ìˆ˜ : ë ˆë²¨ : ë©”ì‹œì§€
```

### í•˜ì´ë¸Œë¦¬ë“œ ì „ëµ ìƒì„¸ íë¦„

```mermaid
flowchart TD
    Start([ìì—°ì–´ ì§ˆë¬¸]) --> Normalize[1. normalize.normalize<br/>ë™ì˜ì–´ ì¹˜í™˜]

    Normalize --> NLUKeyword[2. nlu keyword based<br/>í‚¤ì›Œë“œ ë§¤ì¹­]

    NLUKeyword --> NLUConf{3. nlu confidence<br/>ì‹ ë¢°ë„ >= 0.7?}

    NLUConf -->|Yes| Plan[4. planner make plan<br/>ë¹ ë¥¸ ì²˜ë¦¬]
    NLUConf -->|No| NLULLM[3b. nlu llm based<br/>LLM í˜¸ì¶œ]

    NLULLM --> Plan

    Plan --> SQLGen[5. sqlgen generate<br/>LLM SQL ìƒì„±]

    SQLGen --> TableSuffix[5a. determine suffix<br/>ë‚ ì§œ ë²”ìœ„ ê³„ì‚°]
    TableSuffix --> Prompt[5b. build prompt<br/>ì‹œë§¨í‹± ëª¨ë¸ + GA4 ìŠ¤í‚¤ë§ˆ]
    Prompt --> LLMSQL[5c. call openai<br/>LLM í˜¸ì¶œ]
    LLMSQL --> PostProcess[5d. post process<br/>ì •ë¦¬]

    PostProcess --> LinkToken[6. schema matching token<br/>í† í° + ë³„ì¹­ ë§¤ì¹­]

    LinkToken --> LinkConf{ì‹ ë¢°ë„ >= 0.6?}

    LinkConf -->|Yes| Guard[7. guard parse<br/>SQLGlot íŒŒì‹±]
    LinkConf -->|No| LinkLLM[6b. schema matching llm<br/>LLM í˜¸ì¶œ]

    LinkLLM --> Guard

    Guard --> Safe[8. ensure safe<br/>ê°€ë“œë ˆì¼]
    Safe --> Lint[9. lint check<br/>í’ˆì§ˆ ê²€ì‚¬]

    Lint --> Pipeline[10. run validation<br/>6ë‹¨ê³„ ê²€ì¦]

    Pipeline --> Pipe1[10a. lint]
    Pipe1 --> Pipe2[10b. dryrun]
    Pipe2 --> Pipe3[10c. explain]
    Pipe3 --> Pipe4[10d. get schema]
    Pipe4 --> Pipe5[10e. canary test]
    Pipe5 --> Pipe6[10f. assertions]

    Pipe6 --> Execute[11. execute query<br/>BigQuery ì‹¤í–‰]

    Execute --> Summarize[12. summarize<br/>ê²°ê³¼ ìš”ì•½]

    Summarize --> Response([ì‘ë‹µ ë°˜í™˜])

    style NLUKeyword fill:#e1f5ff
    style NLULLM fill:#fff4e1
    style LinkToken fill:#e1f5ff
    style LinkLLM fill:#fff4e1
    style LLMSQL fill:#ffe1f5
    style Pipeline fill:#f0f0f0
```

### ê° ëª¨ë“ˆì˜ ì£¼ìš” í•¨ìˆ˜

| ëª¨ë“ˆ | ì£¼ìš” í•¨ìˆ˜ | ì…ë ¥ | ì¶œë ¥ |
|------|----------|------|------|
| **normalize.py** | `normalize(text)` | str | (normalized_text, meta) |
| **context.py** | `get_context(conv_id)` | str | dict |
| | `update_context(conv_id, patch)` | str, dict | None |
| **nlu.py** | `extract(q, use_llm)` | str, bool | (intent, slots) |
| | `_extract_keyword_based(q)` | str | (intent, slots) |
| | `_calculate_confidence(q, intent, slots)` | str, str, dict | float |
| | `_extract_llm_based(q)` | str | (intent, slots) |
| **planner.py** | `make_plan(intent, slots, validate)` | str, dict, bool | plan dict |
| | `_load_semantic_config()` | - | config dict |
| | `_validate_metric(metric, config)` | str, dict | None or raise |
| **sqlgen.py** | `generate(plan, question, limit, provider, conv_id)` | dict, str, int, str, str | SQL str |
| | `_determine_table_suffix(plan, question, context)` | dict, str, dict | suffix_info dict |
| | `_build_sql_generation_prompt(...)` | multiple | prompt str |
| | `_call_openai_for_sql(prompt)` | str | SQL str |
| **linking.py** | `schema_link(question, use_llm)` | str, bool | {candidates, confidence, method} |
| | `_schema_link_token_based(question)` | str | {candidates, confidence} |
| | `_schema_link_llm_based(question)` | str | {candidates, confidence} |
| **guard.py** | `parse_sql(sql)` | str | AST or None |
| **validator.py** | `ensure_safe(sql)` | str | None or raise |
| | `lint(sql)` | str | issues [] |
| **validation.py** | `run_pipeline(sql, perform_execute, plan, logger)` | str, bool, dict, logger | ValidationReport |
| | `lint_sql(sql)` | str | StepResult |
| | `dry_run(sql)` | str | StepResult |
| | `schema(sql)` | str | StepResult |
| | `canary(sql, limit_rows)` | str, int | StepResult |
| | `domain_assertions(sql, plan)` | str, dict | StepResult |
| **executor.py** | `run(sql, dry_run)` | str, bool | QueryResult |
| | `materialize(sql)` | str | QueryResult |
| **summarize.py** | `summarize(rows, meta)` | list, dict | str |
| | `summarize_llm(question, sql, meta, provider)` | str, str, dict, str | str |

---

**Made with â¤ï¸ using FastAPI, Vue3, and LLM**
